# ENTERPRISE RAG + AGENTIC SEARCH PLATFORM

An advanced enterprise-grade search platform combining **Retrieval-Augmented Generation (RAG)** with **Agentic Search** capabilities. Features dual search modes, in-memory vector store, and a modern web interface.

## ğŸš€ Key Features

### Dual Search Modes
- **Simple RAG Mode**: Fast, direct retrieval and answer generation
- **Agentic Search Mode**: Intelligent orchestration with:
  - Intent detection (lookup, compare, summarize, analyze)
  - Execution planning and strategy
  - Tool selection and invocation
  - Post-processing and evidence extraction
  - Full action tracking and transparency

### Technical Stack
- **Backend**: FastAPI (Python)
- **Vector Store**: NumPy-based cosine similarity search (in-memory)
- **LLM**: GPT-4o via GitHub Models or OpenAI
- **Embeddings**: text-embedding-3-small
- **Frontend**: Vanilla JavaScript, HTML5, CSS3

## ğŸ“¦ Quick Start

### Prerequisites
- Python 3.9+
- Git

### Installation

```bash
git clone <repository-url>
cd -ENTERPRISE-RAG-AGENTIC-SEARCH-PLATFORM

python -m venv .venv
.\.venv\Scripts\Activate

pip install -r requirements.txt
```

### Configuration

Create a `.env` file in the project root with one of the following:

**Option A: OpenAI API Key (Recommended)**
```bash
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxx
```

**Option B: GitHub Token (Free, 50 requests/day)**
```bash
GITHUB_TOKEN=github_pat_xxxxxxxxxxxxxxxxxxxxxxxx
```

### Running the Application

**Terminal 1 - Backend (Port 8001):**
```bash
.\.venv\Scripts\Activate
python -m uvicorn api.index:app --reload --host 127.0.0.1 --port 8001
```

**Terminal 2 - Frontend (Port 8080):**
```bash
cd public
python -m http.server 8080
```

**Access the app:** http://127.0.0.1:8080

## ğŸ“ Usage

### 1. Upload Documents
- Click the upload icon (ğŸ“)
- Select `.txt` or `.pdf` files
- Documents are indexed immediately (in-memory, ephemeral)

### 2. Query the System

**Simple RAG Mode** - Fast lookups:
- "What is the refund policy?"
- "How many days to return an item?"

**Agentic Mode** - Complex queries:
- "Compare refund policy and cancellation policy"
- "Analyze the refund requirements"
- "Summarize the shipping policy"

## ğŸ—ï¸ Architecture

```
Frontend (public/)
    â†“
API Layer (api/index.py)
    â”œâ”€â”€ /search (RAG + Agentic)
    â”œâ”€â”€ /upload (Document ingestion)
    â””â”€â”€ / (Health check)
    â†“
RAG Engine (src/rag_engine.py)
    â”œâ”€â”€ In-memory vector store
    â”œâ”€â”€ Retrieval via cosine similarity
    â””â”€â”€ Answer generation
```

### Architecture Difference

**Simple RAG**: `rag_engine.generate_answer()` - Direct retrieval + generation

**Agentic Search**: `rag_engine.query()` as a tool â†’ Intent detection â†’ Planning â†’ Execution â†’ Post-processing

See [AGENTIC_ARCHITECTURE.md](AGENTIC_ARCHITECTURE.md) for detailed documentation.

## ğŸ”Œ API Endpoints

### `POST /search`
Unified search endpoint with mode selection.

**Request:**
```json
{
  "query": "Compare refund and cancellation policies",
  "mode": "agentic"  
}
```

**Response (Agentic):**
```json
{
  "mode": "agentic",
  "intent": "compare",
  "agent_plan": {
    "strategy": "Split query into components...",
    "search_queries": ["refund policy", "cancellation policy"]
  },
  "actions_taken": [...],
  "answer": "...",
  "evidence": [...],
  "sources": ["refund_policy.pdf"],
  "confidence": 0.85
}
```

### `POST /upload`
Upload and ingest documents (PDF/TXT).

**Response:**
```json
{
  "message": "Successfully processed filename.pdf. Added 15 chunks to knowledge base.",
  "filename": "filename.pdf",
  "chunks": 15
}
```

## ğŸ› ï¸ Troubleshooting

### Rate Limit Errors
**Problem**: "API Rate Limit Exceeded" with GitHub Token

**Solution**: Switch to OpenAI API key
1. Get key from [platform.openai.com](https://platform.openai.com)
2. Add `OPENAI_API_KEY=sk-...` to `.env`
3. Restart backend

### Connection Errors
- Ensure backend runs on port **8001**
- Frontend should be at `http://127.0.0.1:8080`
- Check both terminals are active

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ api/
â”‚   â””â”€â”€ index.py                    # FastAPI application & endpoints
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ controllers/
â”‚       â”‚   â””â”€â”€ search_controller.py # Request routing
â”‚       â””â”€â”€ services/
â”‚           â”œâ”€â”€ agentic_search.py    # Agentic pipeline
â”‚           â””â”€â”€ llm.py               # LLM client
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ rag_engine.py               # Core RAG engine
â”‚   â”œâ”€â”€ chunker.py                  # Text chunking
â”‚   â”œâ”€â”€ ingest.py                   # Document ingestion
â”‚   â””â”€â”€ llm_client.py               # LLM wrapper
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ index.html                  # Frontend UI
â”‚   â”œâ”€â”€ script.js                   # Frontend logic
â”‚   â””â”€â”€ style.css                   # Styling
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ .env                            # Environment variables (create this)
â””â”€â”€ README.md                       # This file
```

## ğŸš€ Deployment

### Vercel

```bash
npm i -g vercel
vercel --prod
```

**Environment Variables** (Vercel Dashboard):
- Add `GITHUB_TOKEN` or `OPENAI_API_KEY`

**Important Notes**:
- 10-second timeout limit
- In-memory storage (ephemeral)
- Upload smaller files (<20 pages)

## ğŸ“š Documentation

- [HOW_TO_RUN.md](HOW_TO_RUN.md) - Simplified setup guide
- [AGENTIC_ARCHITECTURE.md](AGENTIC_ARCHITECTURE.md) - Architecture details
- [GETTING_STARTED.md](GETTING_STARTED.md) - Comprehensive guide

## ğŸ¯ Future Roadmap

- Persistent storage (Redis/Pinecone)
- Background processing for large documents
- Multi-modal support (images, tables)
- User authentication & access control
- Query analytics & monitoring
- Export conversations

## ğŸ“„ License

MIT License

## ğŸ¤ Contributing

Contributions welcome! Please open an issue or submit a pull request.

## ğŸ“§ Contact

For questions or support, please open an issue on GitHub.
